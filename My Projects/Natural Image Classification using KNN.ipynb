{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Classification using K-Nearest Neighbours\n",
    "\n",
    "Using KNN to classify images is seldom used (if at all)! But here we will create a small model of the same to simply give it a shot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing packages we need\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.neighbors import NearestNeighbors, KNeighborsClassifier'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The process in a nutshell\n",
    "- (1) Create train,valid and test data out of image folders\n",
    "- (2) Flatten our model! Perhaps also use PCA and perform dimension reduction\n",
    "- (2) fit our model for both finding K nearest neighbors and also the classification labels\n",
    "- (3) Count accuracy rate or create a crosstab matrix!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 808 images belonging to 8 classes.\n",
      "Found 160 images belonging to 8 classes.\n",
      "Found 88 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "(from project- Natural Images Classification CNNs)\n",
    "STEP 1: Creating train, test and valid data from image folders using Image Data Generator\n",
    "\n",
    "CREATE VARIABLES WHICH CONTAIN THE PATHS TO THE TRAIN,TEST AND VALIDATE FOLDERS \n",
    "- You can give relative or absolute paths\n",
    "\"\"\"\n",
    "# Here we simply set the path so Keras Image gen can go into these folders \n",
    "train_path = 'C:/Users/Darshil/gitly/Deep-Learning/My Projects/Classification_Natural Images/train'\n",
    "valid_path = 'C:/Users/Darshil/gitly/Deep-Learning/My Projects/Classification_Natural Images/valid'\n",
    "test_path = 'C:/Users/Darshil/gitly/Deep-Learning/My Projects/Classification_Natural Images/test'\n",
    "\n",
    "\"\"\"\n",
    "USING IMAGE DATA GENERATOR : ImageDataGenerator()\n",
    "- Important to understand that what this does is simply go into our directory and go into the class image folders we've created, \n",
    "and then simply find those images\n",
    "Ex: if train/dog has 20 images it will recognize those images and label them as 'dog' I think\n",
    "\n",
    "NOTE: \n",
    "ImageDataGenerator has the following details: \n",
    "- we call the flow_from_directory function which goes into a dir, converts the image and assigns the label\n",
    "- target_size = converts all images into that size (these need to be consistent)\n",
    "- classes = name classes in order and place them in the same order in all 3 folders just to be safe\n",
    "- batch_size = this allows us to iterate over the images X times otherwise too many images in memory\n",
    "\"\"\"\n",
    "\n",
    "all_classes = ['airplane', 'car','cat', 'dog', 'flower', 'fruit', 'motorbike', 'person']\n",
    "\n",
    "#Note make sure you name the classes correctly!\n",
    "train_batches = ImageDataGenerator().flow_from_directory(train_path, target_size=(224,224), classes = all_classes, batch_size = 808)\n",
    "valid_batches = ImageDataGenerator().flow_from_directory(valid_path, target_size=(224,224), classes = all_classes, batch_size = 160)\n",
    "test_batches = ImageDataGenerator().flow_from_directory(test_path, target_size=(224,224), classes = all_classes, batch_size = 88)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data dimensions:  (808, 224, 224, 3)  Training labels dimensions:  (808, 8) \n",
      " Validation data dimensions:  (160, 224, 224, 3)  Valid labels dimensions:  (160, 8) \n",
      " Test data dimensions:  (88, 224, 224, 3)  Test labels dimensions:  (88, 8)\n"
     ]
    }
   ],
   "source": [
    "#Here we create our training, validation and test data\n",
    "training_data_3d, training_data_labels = next(train_batches)\n",
    "valid_data_3d, valid_data_labels = next(valid_batches)\n",
    "test_data_3d, test_data_labels = next(test_batches)\n",
    "\n",
    "#checking dimensions!\n",
    "print ('Training data dimensions: ', training_data_3d.shape, ' Training labels dimensions: ',training_data_labels.shape, '\\n',\n",
    "      'Validation data dimensions: ', valid_data_3d.shape, ' Valid labels dimensions: ',valid_data_labels.shape, '\\n',\n",
    "      'Test data dimensions: ', test_data_3d.shape, ' Test labels dimensions: ',test_data_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2) Flatten data\n",
    "It is vital to reshape our data for the KNN algorithm to calculate distances between different datapoints. <br> \n",
    "- Here each datapoint is an image of dimensions 1x150528\n",
    "- In order to save time and make our model less compuationally expensive, it may be wise to also incorporate dimension reduction using Principal Component Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flattened dimensions \n",
      " ----------------------- \n",
      " training:  (808, 150528) \n",
      " valid (160, 150528) \n",
      " test:  (88, 150528)\n"
     ]
    }
   ],
   "source": [
    "#First we flatten our data\n",
    "training_data =training_data_3d.reshape(808,150528)\n",
    "valid_data = valid_data_3d.reshape(160,150528)\n",
    "test_data = test_data_3d.reshape(88,150528)\n",
    "\n",
    "print ('Flattened dimensions','\\n',\n",
    "       '----------------------- \\n',\n",
    "      'training: ', training_data.shape, '\\n',\n",
    "       'valid', valid_data.shape, '\\n',\n",
    "      'test: ',test_data.shape )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (3) Now we do the following:\n",
    "- (i) fit model to find nearest neighbors\n",
    "- (ii) use KNN to classify test data\n",
    "- (iii) creating a confusion matrix!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[    0.        , 21030.71113871, 22439.20513298, 22472.96197656,\n",
       "         22699.82270856, 22805.07717593, 23461.12429105]]),\n",
       " array([[331, 517, 677, 662, 746, 329, 180]], dtype=int64))"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "(i)  fit model to find nearest neighbors\n",
    "\"\"\"\n",
    "#initializing model\n",
    "nearest_imgs= NearestNeighbors(n_neighbors=7)\n",
    "\n",
    "#fitting our data\n",
    "nearest_imgs.fit(training_data)\n",
    "\n",
    "\"\"\"\n",
    "Find K Nearest neighbors\n",
    "- here we can predict on a test image\n",
    "- Note that it .kneighbors returns 2 arrays, \n",
    "    - first array : distances between test image and all K nearest images\n",
    "    - the indexes of the same images in test_data so you can see\n",
    "\"\"\"\n",
    "\n",
    "prediction_test = nearest_imgs.kneighbors([test_data[4]])\n",
    "prediction_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  6.,   6.,   6., ...,   6.,   6.,   6.],\n",
       "       [ 26.,  23.,  42., ...,  56.,  57.,  51.],\n",
       "       [ 27.,  29.,  24., ..., 137., 147., 136.],\n",
       "       ...,\n",
       "       [ 33.,  37.,  40., ...,  58.,  37.,  32.],\n",
       "       [ 53.,  45.,  43., ...,  49.,  40.,  33.],\n",
       "       [ 25.,  35.,  27., ...,  27.,  34.,  40.]], dtype=float32)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#these are the following images (each row is an image) that are the closest\n",
    "training_data[[list(prediction_test)[1][0]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=7, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "(ii)  use KNN to classify test data\n",
    "\n",
    "- Important to note that we need ton convert our one-hot coded labels to integers\n",
    "(https://stackoverflow.com/questions/42497340/how-to-convert-one-hot-encodings-into-integers)\n",
    "\"\"\"\n",
    "#Initialize our KNN model with 5 neighbours and define the euclidean distance\n",
    "knn = KNeighborsClassifier(n_neighbors =7, \n",
    "                       p = 2)# p=2 for euclidean distance\n",
    "\n",
    "#converting our one-hot coded labels to integers\n",
    "knn_training_labels = [np.where(r==1)[0][0] for r in training_data_labels]\n",
    "knn_valid_labels = [np.where(r==1)[0][0] for r in valid_data_labels]\n",
    "knn_test_labels = [np.where(r==1)[0][0] for r in test_data_labels]\n",
    "\n",
    "\n",
    "#fitting our model\n",
    "knn.fit(training_data,knn_training_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2], dtype=int64)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lets try out predicting for a random image in test_data \n",
    "knn.predict([test_data[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicting on the entire valid dataset\n",
    "test_preds = knn.predict(valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[18,  0,  2,  0,  0,  0,  0,  0],\n",
       "       [ 3,  8,  5,  3,  0,  1,  0,  0],\n",
       "       [ 0,  0, 20,  0,  0,  0,  0,  0],\n",
       "       [ 2,  0,  9,  6,  0,  0,  0,  3],\n",
       "       [ 4,  1,  6,  1,  6,  0,  0,  2],\n",
       "       [ 0,  0,  0,  0,  0, 20,  0,  0],\n",
       "       [ 4,  0, 11,  2,  0,  0,  3,  0],\n",
       "       [ 0,  0,  1,  2,  0,  0,  0, 17]], dtype=int64)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating a confusion matrix\n",
    "confusion_matrix(knn_valid_labels, test_preds, labels=[0,1,2,3,4,5,6,7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda3]",
   "language": "python",
   "name": "conda-env-Anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
