{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Convolutional Neural Networks Using Keras Framework\n",
    "\n",
    "Reference Source: https://www.youtube.com/watch?v=NyYM6HnyX8I&list=PLBtyBPTlyC7tnpPDkp_E2JgIgIQSbugJL&index=15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, Flatten\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "(mnist_train_images, mnist_train_labels), (mnist_test_images, mnist_test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "if K.image_data_format() == \"channels_first\":\n",
    "    train_images = mnist_train_images.reshape(mnist_train_images.shape[0], 1, 28,28)\n",
    "    test_images = mnist_test_images.reshape(mnist_test_images.shape[0],1,28,28)\n",
    "    input_shape = (1,28,28)\n",
    "    \n",
    "else:\n",
    "    train_images = mnist_train_images.reshape(mnist_train_images.shape[0], 28,28,1)\n",
    "    test_images = mnist_test_images.reshape(mnist_test_images.shape[0], 28,28,1)\n",
    "    input_shape = (28,28,1)\n",
    "\n",
    "# normalizing data\n",
    "train_images = train_images.astype('float32')\n",
    "test_images = test_images.astype('float32')\n",
    "train_images = train_images/255\n",
    "test_images = test_images/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = keras.utils.to_categorical(mnist_train_labels,10)\n",
    "test_labels = keras.utils.to_categorical(mnist_test_labels,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1faa4e57470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# taking this directly from reference article\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def display_sample(num):\n",
    "    #print the one-hot array of this samples label\n",
    "    print (train_labels[num])\n",
    "    \n",
    "    # print the label copnverted back to a number\n",
    "    label = train_labels[num].argmax(axis=0)\n",
    "    \n",
    "    #reshape the 768 values to a 28x28 image\n",
    "    image = train_images[num].reshape([28,28])\n",
    "    plt.title('Sample %d Label: %d' % (num,label))\n",
    "    plt.imshow(image, cmap = plt.get_cmap('gray_r'))\n",
    "    plt.show()\n",
    "    %matplotlib inline  \n",
    "\n",
    "display_sample(4)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building out the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32,kernel_size=(3,3), activation='relu', input_shape = input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128,activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Dense(10, activation = 'softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 5408)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               692352    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 693,962\n",
      "Trainable params: 693,962\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'categorical_crossentropy',\n",
    "             optimizer = 'adam',\n",
    "             metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_images,train_labels,\n",
    "                   batch_size = 32,\n",
    "                   epochs=1,\n",
    "                   verbose=2,\n",
    "                   validation_data = (test_images, test_labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda3]",
   "language": "python",
   "name": "conda-env-Anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
