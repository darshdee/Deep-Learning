{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sattelite Images\n",
    "\n",
    "[Kaggle Source](https://www.kaggle.com/rhammell/planesnet) <br>\n",
    "[Other Clustering Project](https://medium.com/@h4k1m0u/clustering-a-satellite-image-with-scikit-learn-14adb2ca3790) <br>\n",
    "[Image Source](https://developers.planet.com/planetschool/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Darshil\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#----------data preprocessing-------\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "#------Neural Networks-----------\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, Flatten\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing\n",
    "- 1) reading in dataset\n",
    "- 2) Viewing an image\n",
    "- 3) Converting our \"data\" column (with lists of size 1x1200, 400 RGB each) into a dataframe of size 32000x1200\n",
    "- 4) UNIFORMLY create new data out of dataframe and convert dataframe to numpy array of size num_datax20x20x3 \n",
    "- 5) Split into training and testing and we need to one-hot code our test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>labels</th>\n",
       "      <th>locations</th>\n",
       "      <th>scene_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[206, 195, 187, 183, 177, 175, 174, 193, 198, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[-118.40497658522878, 33.940618514147936]</td>\n",
       "      <td>20170620_175442_0e30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[215, 209, 200, 196, 192, 197, 205, 168, 155, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[-122.392469714, 37.6176425378]</td>\n",
       "      <td>20161212_180859_0e30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[204, 214, 220, 219, 213, 205, 198, 193, 199, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[-122.397578597, 37.6209247852]</td>\n",
       "      <td>20170524_181349_0e2f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[179, 174, 179, 178, 173, 170, 168, 168, 168, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[-122.214849831, 37.7203378331]</td>\n",
       "      <td>20161110_180707_0e1f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[222, 222, 218, 214, 208, 205, 207, 206, 206, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[-117.862173435, 33.6796854072]</td>\n",
       "      <td>20160813_184932_0c64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                data  labels  \\\n",
       "0  [206, 195, 187, 183, 177, 175, 174, 193, 198, ...       1   \n",
       "1  [215, 209, 200, 196, 192, 197, 205, 168, 155, ...       1   \n",
       "2  [204, 214, 220, 219, 213, 205, 198, 193, 199, ...       1   \n",
       "3  [179, 174, 179, 178, 173, 170, 168, 168, 168, ...       1   \n",
       "4  [222, 222, 218, 214, 208, 205, 207, 206, 206, ...       1   \n",
       "\n",
       "                                   locations             scene_ids  \n",
       "0  [-118.40497658522878, 33.940618514147936]  20170620_175442_0e30  \n",
       "1            [-122.392469714, 37.6176425378]  20161212_180859_0e30  \n",
       "2            [-122.397578597, 37.6209247852]  20170524_181349_0e2f  \n",
       "3            [-122.214849831, 37.7203378331]  20161110_180707_0e1f  \n",
       "4            [-117.862173435, 33.6796854072]  20160813_184932_0c64  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "1. Reading in Json file\n",
    "\"\"\"\n",
    "data_df = pd.read_json('C:/Users/Darshil/gitly/Deep-Learning/My Projects/sattelite_CNN/planesnet.json')\n",
    "\n",
    "#lets take a look at our data\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the image vector 1200 \n",
      " ----------------------------------\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\" \n",
    "Lets take a look at dataframe data_df\n",
    "-----------------------------\n",
    "\n",
    "- Data  : a list of 1200 pixel values of each image\n",
    "- labels : 0 or 1 for plane or no-plane in the image\n",
    "Everything else for now is redundant\n",
    "\n",
    "\n",
    "2. Viewing an image\n",
    "\"\"\"\n",
    "\n",
    "#data column first image\n",
    "print ('The length of the image vector', len(data_df['data'].iloc[1,]), '\\n', \n",
    "       '----------------------------------')\n",
    "\n",
    "#Lets take a look at the image!\n",
    "\n",
    "image_num = 200\n",
    "a = np.array(data_df.iloc[image_num,0]).reshape(20,20,3)\n",
    "plt.imshow(a)\n",
    "plt.title('Image number is: {}'.format(image_num))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1191</th>\n",
       "      <th>1192</th>\n",
       "      <th>1193</th>\n",
       "      <th>1194</th>\n",
       "      <th>1195</th>\n",
       "      <th>1196</th>\n",
       "      <th>1197</th>\n",
       "      <th>1198</th>\n",
       "      <th>1199</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>206</td>\n",
       "      <td>195</td>\n",
       "      <td>187</td>\n",
       "      <td>183</td>\n",
       "      <td>177</td>\n",
       "      <td>175</td>\n",
       "      <td>174</td>\n",
       "      <td>193</td>\n",
       "      <td>198</td>\n",
       "      <td>197</td>\n",
       "      <td>...</td>\n",
       "      <td>191</td>\n",
       "      <td>193</td>\n",
       "      <td>197</td>\n",
       "      <td>196</td>\n",
       "      <td>198</td>\n",
       "      <td>231</td>\n",
       "      <td>224</td>\n",
       "      <td>194</td>\n",
       "      <td>164</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>215</td>\n",
       "      <td>209</td>\n",
       "      <td>200</td>\n",
       "      <td>196</td>\n",
       "      <td>192</td>\n",
       "      <td>197</td>\n",
       "      <td>205</td>\n",
       "      <td>168</td>\n",
       "      <td>155</td>\n",
       "      <td>160</td>\n",
       "      <td>...</td>\n",
       "      <td>190</td>\n",
       "      <td>185</td>\n",
       "      <td>182</td>\n",
       "      <td>192</td>\n",
       "      <td>201</td>\n",
       "      <td>204</td>\n",
       "      <td>205</td>\n",
       "      <td>207</td>\n",
       "      <td>210</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>204</td>\n",
       "      <td>214</td>\n",
       "      <td>220</td>\n",
       "      <td>219</td>\n",
       "      <td>213</td>\n",
       "      <td>205</td>\n",
       "      <td>198</td>\n",
       "      <td>193</td>\n",
       "      <td>199</td>\n",
       "      <td>186</td>\n",
       "      <td>...</td>\n",
       "      <td>171</td>\n",
       "      <td>174</td>\n",
       "      <td>173</td>\n",
       "      <td>174</td>\n",
       "      <td>176</td>\n",
       "      <td>171</td>\n",
       "      <td>167</td>\n",
       "      <td>163</td>\n",
       "      <td>157</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>179</td>\n",
       "      <td>174</td>\n",
       "      <td>179</td>\n",
       "      <td>178</td>\n",
       "      <td>173</td>\n",
       "      <td>170</td>\n",
       "      <td>168</td>\n",
       "      <td>168</td>\n",
       "      <td>168</td>\n",
       "      <td>170</td>\n",
       "      <td>...</td>\n",
       "      <td>150</td>\n",
       "      <td>152</td>\n",
       "      <td>164</td>\n",
       "      <td>171</td>\n",
       "      <td>171</td>\n",
       "      <td>171</td>\n",
       "      <td>170</td>\n",
       "      <td>169</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>222</td>\n",
       "      <td>222</td>\n",
       "      <td>218</td>\n",
       "      <td>214</td>\n",
       "      <td>208</td>\n",
       "      <td>205</td>\n",
       "      <td>207</td>\n",
       "      <td>206</td>\n",
       "      <td>206</td>\n",
       "      <td>207</td>\n",
       "      <td>...</td>\n",
       "      <td>164</td>\n",
       "      <td>164</td>\n",
       "      <td>161</td>\n",
       "      <td>156</td>\n",
       "      <td>163</td>\n",
       "      <td>164</td>\n",
       "      <td>166</td>\n",
       "      <td>158</td>\n",
       "      <td>147</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3    4    5    6    7    8    9   ...    1191  1192  1193  \\\n",
       "0  206  195  187  183  177  175  174  193  198  197   ...     191   193   197   \n",
       "1  215  209  200  196  192  197  205  168  155  160   ...     190   185   182   \n",
       "2  204  214  220  219  213  205  198  193  199  186   ...     171   174   173   \n",
       "3  179  174  179  178  173  170  168  168  168  170   ...     150   152   164   \n",
       "4  222  222  218  214  208  205  207  206  206  207   ...     164   164   161   \n",
       "\n",
       "   1194  1195  1196  1197  1198  1199  labels  \n",
       "0   196   198   231   224   194   164       1  \n",
       "1   192   201   204   205   207   210       1  \n",
       "2   174   176   171   167   163   157       1  \n",
       "3   171   171   171   170   169   163       1  \n",
       "4   156   163   164   166   158   147       1  \n",
       "\n",
       "[5 rows x 1201 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "3. Pandas series to dataframe and then we need to randomly shuffle \n",
    "(https://stackoverflow.com/questions/45901018/convert-pandas-series-of-lists-to-dataframe)\n",
    "\n",
    "We're also going to add the label column to our pixel_df\n",
    "\"\"\"\n",
    "#Now we're going to transpose s\n",
    "pixel_df = pd.DataFrame.from_items(zip(data_df['data'].index, data_df['data'].values)).T\n",
    "\n",
    "#adding the label column\n",
    "pixel_df['labels'] = data_df['labels']\n",
    "pixel_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confirming that our dataset is uniformly distributed \n",
      " --------------------------\n",
      "1    8000\n",
      "0    7999\n",
      "Name: labels, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Convert Pandas dataframe of size 32000x1200 to numpy array of size 32Kx1200\n",
    "NOTE! We need to reshape out data to size number_of_datapoints x 20x20x3 where 20x20x3 are the dimensions \n",
    "..for each colored image\n",
    "\n",
    "Furthermore, its important to understand that because the labels in our dataset are not uniform, ie: there are 24K images \n",
    "...with no planes and only 8K images with planes in them, it is important to uniformly distribute the data to train on\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "#------------creating a uniform dataset-------------\n",
    "\n",
    "#random seed\n",
    "random.seed(2)\n",
    "#We create a new dataframe that we will append to \n",
    "new_df = pd.DataFrame(index=[0], columns=pixel_df.columns)\n",
    "new_df = new_df.fillna(0)\n",
    "\n",
    "#determine size of dataset (can go max 8K for label==1)\n",
    "size_dataset = 16000\n",
    "\n",
    "for x in list(set(pixel_df['labels'])):\n",
    "    \n",
    "    #first we subset the datatframe\n",
    "    a = pixel_df[pixel_df['labels']==x]\n",
    "    \n",
    "    #randomly choose N/2 indices\n",
    "    rands = random.sample(list(a.index),int(size_dataset/2))\n",
    "    \n",
    "    #pick the indices\n",
    "    b = a.loc[rands] \n",
    "    \n",
    "    #append to existing dataframe \n",
    "    new_df = pd.concat([new_df,b])\n",
    "    \n",
    "    #dropping first row which was just initialized to 0\n",
    "    new_df = new_df.iloc[1:,:].dropna(axis=0)\n",
    "    \n",
    "#RANDOMLY SHUFFLE AGAIN\n",
    "rands1 = random.sample(list(new_df.index),size_dataset-1)\n",
    "new_df = new_df.loc[rands1]\n",
    "        \n",
    "print ('Confirming that our dataset is uniformly distributed', '\\n', \n",
    "       '--------------------------')\n",
    "print (new_df['labels'].value_counts(dropna=False))\n",
    "\n",
    "shuffled_pixel_df= new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training data:  15200 \n",
      " Size of training data labels:  15200 \n",
      " \n",
      "\n",
      "Size of test data:  799 \n",
      " Size of test data labels:  799\n",
      "Confirming that the training and test data sizes equal to total size of dataset:  15999\n"
     ]
    }
   ],
   "source": [
    "#---determine training and test data sizes-----\n",
    "training_size = int(0.95 * size_dataset)\n",
    "\n",
    "#-----training data-----\n",
    "training_data = np.array(shuffled_pixel_df.iloc[0:training_size,:1200])\n",
    "training_data_labels = np.array(pd.get_dummies(shuffled_pixel_df.iloc[0:training_size,1200]))  #one-hot coding and then converting to numpy\n",
    "print ('Size of training data: ',training_data.shape[0], '\\n',\n",
    "      'Size of training data labels: ',training_data_labels.shape[0] , '\\n \\n')\n",
    "\n",
    "#-----test data-----\n",
    "test_data = np.array(shuffled_pixel_df.iloc[training_size:,:1200])\n",
    "test_data_labels = np.array(pd.get_dummies(shuffled_pixel_df.iloc[training_size:,1200]))\n",
    "print ('Size of test data: ',test_data.shape[0], '\\n',\n",
    "      'Size of test data labels: ',test_data_labels.shape[0] )\n",
    "\n",
    "\n",
    "print ('Confirming that the training and test data sizes equal to total size of dataset: ', training_data.shape[0] + test_data.shape[0])\n",
    "\n",
    "\n",
    "\n",
    "#reshaping our training and test data HERE!\n",
    "training_pixel_np = training_data.reshape(training_size,20,20,3)\n",
    "test_pixel_np = test_data.reshape(test_data.shape[0],20,20,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape after reshaping:  (15200, 20, 20, 3) \n",
      " Test data shape after reshaping:  (799, 20, 20, 3)\n"
     ]
    }
   ],
   "source": [
    "print ('Training data shape after reshaping: ', training_pixel_np.shape,'\\n',\n",
    "'Test data shape after reshaping: ', test_pixel_np.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network:  Model Without Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32,kernel_size=(3,3), activation='relu', input_shape = (20,20,3)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128,activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(2, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 18, 18, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 9, 9, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 9, 9, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2592)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               331904    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 333,058\n",
      "Trainable params: 333,058\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#print out model summary\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy',\n",
    "             optimizer = 'adam',\n",
    "             metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15200 samples, validate on 799 samples\n",
      "Epoch 1/10\n",
      " 5000/15200 [========>.....................] - ETA: 3s - loss: 4.6202 - acc: 0.6976"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-42d96d8c40de>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m                    \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                    \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m                    validation_data = (test_pixel_np, test_data_labels))\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1040\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1042\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1043\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1044\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    203\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 205\u001b[1;33m                 \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    206\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mcallback_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m                     \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    111\u001b[0m         \u001b[0mt_before_callbacks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 113\u001b[1;33m             \u001b[0mcallback\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    114\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_delta_ts_batch_end\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mt_before_callbacks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m         \u001b[0mdelta_t_median\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_delta_ts_batch_end\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    326\u001b[0m         \u001b[1;31m# will be handled by on_epoch_end.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    327\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseen\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 328\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    329\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mon_epoch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\utils\\generic_utils.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, current, values)\u001b[0m\n\u001b[0;32m    422\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    423\u001b[0m             \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 424\u001b[1;33m             \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    425\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    426\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\ipykernel\\iostream.py\u001b[0m in \u001b[0;36mflush\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    347\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpub_thread\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mschedule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    348\u001b[0m                 \u001b[1;31m# and give a timeout to avoid\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 349\u001b[1;33m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mevt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflush_timeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    350\u001b[0m                     \u001b[1;31m# write directly to __stderr__ instead of warning because\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    351\u001b[0m                     \u001b[1;31m# if this is happening sys.stderr may be the problem.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    550\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 551\u001b[1;33m                 \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    552\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    553\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    297\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 299\u001b[1;33m                     \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    300\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(training_pixel_np,training_data_labels,\n",
    "                   batch_size = 200,\n",
    "                   epochs=10,\n",
    "                   verbose=1,\n",
    "                   validation_data = (test_pixel_np, test_data_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lets take random images and predict\n",
    "preds = model.predict(training_pixel_np[1:10])\n",
    "np.round(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network:  Model Using Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 18, 18, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 9, 9, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 9, 9, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 2592)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               331904    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 349,570\n",
      "Trainable params: 349,570\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32,kernel_size=(3,3), activation='relu', input_shape = (20,20,3)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128,activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(128,activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(2, activation = 'softmax'))\n",
    "\n",
    "#print out model summary\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy',\n",
    "             optimizer = 'adam',\n",
    "             metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_gen = ImageDataGenerator(\n",
    "    #featurewise_center=True,\n",
    "    #featurewise_std_normalization=True,\n",
    "    rescale=1./255,\n",
    "    rotation_range=15,   #rotate images\n",
    "    width_shift_range=.15,\n",
    "    height_shift_range=.15,\n",
    "    horizontal_flip=True)   #flip horizontally\n",
    "\n",
    "#training the image preprocessing\n",
    "image_gen.fit(training_pixel_np, augment=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "475/475 [==============================] - 58s 121ms/step - loss: 0.4732 - acc: 0.7696 - val_loss: 6.9355 - val_acc: 0.5582\n",
      "Epoch 2/10\n",
      "475/475 [==============================] - 56s 118ms/step - loss: 0.4597 - acc: 0.7788 - val_loss: 7.3108 - val_acc: 0.5357\n",
      "Epoch 3/10\n",
      "475/475 [==============================] - 57s 120ms/step - loss: 0.4510 - acc: 0.7850 - val_loss: 6.8284 - val_acc: 0.5645\n",
      "Epoch 4/10\n",
      "475/475 [==============================] - 56s 118ms/step - loss: 0.4426 - acc: 0.7908 - val_loss: 7.0974 - val_acc: 0.5569\n",
      "Epoch 5/10\n",
      "475/475 [==============================] - 57s 119ms/step - loss: 0.4326 - acc: 0.7980 - val_loss: 6.3726 - val_acc: 0.5920\n",
      "Epoch 6/10\n",
      "251/475 [==============>...............] - ETA: 27s - loss: 0.4291 - acc: 0.7997"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-e09287afc0ce>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m           \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m           validation_data = (test_pixel_np, test_data_labels))\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1424\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1425\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1426\u001b[1;33m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1427\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1428\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m    153\u001b[0m             \u001b[0mbatch_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 155\u001b[1;33m                 \u001b[0mgenerator_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    156\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'__len__'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\utils\\data_utils.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    785\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    786\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 787\u001b[1;33m                     \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    788\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    789\u001b[0m         \u001b[1;31m# Make sure to rethrow the first exception in the queue, if any\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "HOW DATA AUGMENTATION WORKS?\n",
    "Data augmentation works as follows: at each learning epoch transformations with randomly \n",
    "selected parameters within the specified range are applied to all original images in the training set. \n",
    "After an epoch is completed, i.e. after having exposed a learning algorithm to the entire set of training data, \n",
    "the next learning epoch is started and training data is once again augmented by applying specified transformations \n",
    "to the original training data.\n",
    "\n",
    "Important parameters: \n",
    "batch_size = selected batch of training data fed to NN\n",
    "steps_per_epoch = batch size forward and back propogated this many times for each epoch. \n",
    "   ...I think this number = number of augmented images for each image\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "model.fit_generator(image_gen.flow(training_pixel_np, training_data_labels, batch_size=200),           \n",
    "          steps_per_epoch = training_pixel_np.shape[0]/32,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          validation_data = (test_pixel_np, test_data_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lets take random images and predict\n",
    "a = model.predict(training_pixel_np[1:15])\n",
    "np.round(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda3]",
   "language": "python",
   "name": "conda-env-Anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
