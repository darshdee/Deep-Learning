{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Housing Prices Using a Neural Network\n",
    "\n",
    "This project will cover basics of regression using a neural network to predict housing prices, training on the Boston housing prices dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/aymericdamien/TensorFlow-Examples/blob/master/notebooks/2_BasicModels/linear_regression.ipynb\n",
    "# https://medium.com/@haydar_ai/learning-data-science-day-9-linear-regression-on-boston-housing-dataset-cd62a80775ef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# We'll just import the boston housing dataset from sklearn.dataset\n",
    "- Remember that the training data does not include the price \n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_boston\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# loading in training data only \n",
    "boston_data = load_boston()\n",
    "boston_df =pd.DataFrame(boston_data.data)\n",
    "boston_df['PRICE'] = boston_data.target\n",
    "boston_df.head()\n",
    "\n",
    "tf.set_random_seed(1)\n",
    "\n",
    "# here we convert the dataframe into numpy matrix and define the x, y data\n",
    "boston_df_without_price = boston_df.drop(['PRICE'], axis=1)\n",
    "\n",
    "training_boston_x= boston_df_without_price.values\n",
    "training_boston_y = boston_df['PRICE'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Finished!\n",
      "Training cost= 151.17615 W= [[ 1.08181596e-01]\n",
      " [-1.17458299e-01]\n",
      " [-1.87981236e+00]\n",
      " [ 3.17177629e+00]\n",
      " [-1.46679819e+00]\n",
      " [-2.96776503e-01]\n",
      " [ 1.10750474e-01]\n",
      " [-1.92724138e-01]\n",
      " [-1.69154310e+00]\n",
      " [ 1.18187368e-01]\n",
      " [ 5.22914529e-01]\n",
      " [-6.16591773e-04]\n",
      " [-6.81648701e-02]] b= [[-0.7991367]]\n",
      "The predicted value is:  [[24.42299]]\n"
     ]
    }
   ],
   "source": [
    "# Lets set up the computation graph here\n",
    "\n",
    "# inputs for A0\n",
    "# X = tf.placeholder(tf.float32, shape = (506, 13))\n",
    "# Y= tf.placeholder(tf.float32, shape = (506,))\n",
    "\n",
    "X = tf.placeholder(\"float\")\n",
    "Y = tf.placeholder(\"float\")\n",
    "# weights for output layer\n",
    "wL = tf.Variable(tf.random_normal([13,1]))\n",
    "bL = tf.Variable(tf.random_normal([1,1]))\n",
    "\n",
    "# Set up the linear model\n",
    "prediction = tf.add(tf.matmul(X,wL), bL)\n",
    "\n",
    "# Now lets set up a cost function- remember that this is a regression problem so we can use the mean squared error\n",
    "# Also number of samples\n",
    "n_samples = training_boston_x.shape[0]\n",
    "\n",
    "# Mean squared error = sum(yhat - y)**2 / m,  cost is as follows:  \n",
    "cost = tf.reduce_mean(tf.square(prediction-Y))\n",
    "\n",
    "# Gradient descent\n",
    "learning_rate = 0.05\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "\n",
    "# Initialize the variables (i.e. assign their default value)\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "lfp = []\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)    \n",
    "    \n",
    "#     Lets begin training    \n",
    "    for epoch in range(1000):        \n",
    "        _, loss = sess.run([optimizer,cost],  feed_dict = {X: training_boston_x, Y: training_boston_y})\n",
    "        lfp.append(loss)\n",
    "\n",
    "                                \n",
    "#         if (epoch+1) % 100 == 0:        \n",
    "#             c = sess.run(cost, feed_dict={X: training_boston_x, Y:training_boston_y})\n",
    "#             print (\"Epoch:\", '%04d' % (epoch+1), \"cost=\", \"{:.9f}\".format(c), \"W=\", sess.run(wL), \"b=\", sess.run(bL))\n",
    "            \n",
    "    print (\"Optimization Finished!\")\n",
    "    training_cost = sess.run(cost, feed_dict={X: training_boston_x, Y: training_boston_y})\n",
    "    print (\"Training cost=\", training_cost, \"W=\", sess.run(wL), \"b=\", sess.run(bL))\n",
    "    \n",
    "\n",
    "    \"\"\"\n",
    "    PREDICTION\n",
    "    - Now we use the trained model to predict on some inputs\n",
    "    - for now we'll just pick a row from the existing training data to make it work\n",
    "    \"\"\"    \n",
    "    \n",
    "    row = 18\n",
    "    px = training_boston_x[row,:]\n",
    "    py = training_boston_y[row]\n",
    "    print (\"The predicted value is: \", sess.run(prediction, feed_dict = {X: [px], Y: py }))   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph the Loss Value  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2209c524128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost function ends at:  114.08734\n"
     ]
    }
   ],
   "source": [
    "plt.plot(lfp, '-', label='Cost Value vs Number of Iterations')\n",
    "# plt.plot(train_X, sess.run(W) * train_X + sess.run(b), label='Fitted line')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "%matplotlib inline\n",
    "\n",
    "print (\"cost function ends at: \", str(lfp[len(lfp)-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>PRICE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.02985</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.430</td>\n",
       "      <td>58.7</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.12</td>\n",
       "      <td>5.21</td>\n",
       "      <td>28.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.08829</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.524</td>\n",
       "      <td>6.012</td>\n",
       "      <td>66.6</td>\n",
       "      <td>5.5605</td>\n",
       "      <td>5.0</td>\n",
       "      <td>311.0</td>\n",
       "      <td>15.2</td>\n",
       "      <td>395.60</td>\n",
       "      <td>12.43</td>\n",
       "      <td>22.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.14455</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.524</td>\n",
       "      <td>6.172</td>\n",
       "      <td>96.1</td>\n",
       "      <td>5.9505</td>\n",
       "      <td>5.0</td>\n",
       "      <td>311.0</td>\n",
       "      <td>15.2</td>\n",
       "      <td>396.90</td>\n",
       "      <td>19.15</td>\n",
       "      <td>27.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.21124</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.524</td>\n",
       "      <td>5.631</td>\n",
       "      <td>100.0</td>\n",
       "      <td>6.0821</td>\n",
       "      <td>5.0</td>\n",
       "      <td>311.0</td>\n",
       "      <td>15.2</td>\n",
       "      <td>386.63</td>\n",
       "      <td>29.93</td>\n",
       "      <td>16.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.17004</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.524</td>\n",
       "      <td>6.004</td>\n",
       "      <td>85.9</td>\n",
       "      <td>6.5921</td>\n",
       "      <td>5.0</td>\n",
       "      <td>311.0</td>\n",
       "      <td>15.2</td>\n",
       "      <td>386.71</td>\n",
       "      <td>17.10</td>\n",
       "      <td>18.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.22489</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.524</td>\n",
       "      <td>6.377</td>\n",
       "      <td>94.3</td>\n",
       "      <td>6.3467</td>\n",
       "      <td>5.0</td>\n",
       "      <td>311.0</td>\n",
       "      <td>15.2</td>\n",
       "      <td>392.52</td>\n",
       "      <td>20.45</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.11747</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.524</td>\n",
       "      <td>6.009</td>\n",
       "      <td>82.9</td>\n",
       "      <td>6.2267</td>\n",
       "      <td>5.0</td>\n",
       "      <td>311.0</td>\n",
       "      <td>15.2</td>\n",
       "      <td>396.90</td>\n",
       "      <td>13.27</td>\n",
       "      <td>18.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.09378</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.524</td>\n",
       "      <td>5.889</td>\n",
       "      <td>39.0</td>\n",
       "      <td>5.4509</td>\n",
       "      <td>5.0</td>\n",
       "      <td>311.0</td>\n",
       "      <td>15.2</td>\n",
       "      <td>390.50</td>\n",
       "      <td>15.71</td>\n",
       "      <td>21.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.62976</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>5.949</td>\n",
       "      <td>61.8</td>\n",
       "      <td>4.7075</td>\n",
       "      <td>4.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>8.26</td>\n",
       "      <td>20.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.63796</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.096</td>\n",
       "      <td>84.5</td>\n",
       "      <td>4.4619</td>\n",
       "      <td>4.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>380.02</td>\n",
       "      <td>10.26</td>\n",
       "      <td>18.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.62739</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>5.834</td>\n",
       "      <td>56.5</td>\n",
       "      <td>4.4986</td>\n",
       "      <td>4.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>395.62</td>\n",
       "      <td>8.47</td>\n",
       "      <td>19.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.05393</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>5.935</td>\n",
       "      <td>29.3</td>\n",
       "      <td>4.4986</td>\n",
       "      <td>4.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>386.85</td>\n",
       "      <td>6.58</td>\n",
       "      <td>23.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.78420</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>5.990</td>\n",
       "      <td>81.7</td>\n",
       "      <td>4.2579</td>\n",
       "      <td>4.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>386.75</td>\n",
       "      <td>14.67</td>\n",
       "      <td>17.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.80271</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>5.456</td>\n",
       "      <td>36.6</td>\n",
       "      <td>3.7965</td>\n",
       "      <td>4.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>288.99</td>\n",
       "      <td>11.69</td>\n",
       "      <td>20.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0     1     2    3      4      5      6       7    8      9    10  \\\n",
       "0   0.00632  18.0  2.31  0.0  0.538  6.575   65.2  4.0900  1.0  296.0  15.3   \n",
       "1   0.02731   0.0  7.07  0.0  0.469  6.421   78.9  4.9671  2.0  242.0  17.8   \n",
       "2   0.02729   0.0  7.07  0.0  0.469  7.185   61.1  4.9671  2.0  242.0  17.8   \n",
       "3   0.03237   0.0  2.18  0.0  0.458  6.998   45.8  6.0622  3.0  222.0  18.7   \n",
       "4   0.06905   0.0  2.18  0.0  0.458  7.147   54.2  6.0622  3.0  222.0  18.7   \n",
       "5   0.02985   0.0  2.18  0.0  0.458  6.430   58.7  6.0622  3.0  222.0  18.7   \n",
       "6   0.08829  12.5  7.87  0.0  0.524  6.012   66.6  5.5605  5.0  311.0  15.2   \n",
       "7   0.14455  12.5  7.87  0.0  0.524  6.172   96.1  5.9505  5.0  311.0  15.2   \n",
       "8   0.21124  12.5  7.87  0.0  0.524  5.631  100.0  6.0821  5.0  311.0  15.2   \n",
       "9   0.17004  12.5  7.87  0.0  0.524  6.004   85.9  6.5921  5.0  311.0  15.2   \n",
       "10  0.22489  12.5  7.87  0.0  0.524  6.377   94.3  6.3467  5.0  311.0  15.2   \n",
       "11  0.11747  12.5  7.87  0.0  0.524  6.009   82.9  6.2267  5.0  311.0  15.2   \n",
       "12  0.09378  12.5  7.87  0.0  0.524  5.889   39.0  5.4509  5.0  311.0  15.2   \n",
       "13  0.62976   0.0  8.14  0.0  0.538  5.949   61.8  4.7075  4.0  307.0  21.0   \n",
       "14  0.63796   0.0  8.14  0.0  0.538  6.096   84.5  4.4619  4.0  307.0  21.0   \n",
       "15  0.62739   0.0  8.14  0.0  0.538  5.834   56.5  4.4986  4.0  307.0  21.0   \n",
       "16  1.05393   0.0  8.14  0.0  0.538  5.935   29.3  4.4986  4.0  307.0  21.0   \n",
       "17  0.78420   0.0  8.14  0.0  0.538  5.990   81.7  4.2579  4.0  307.0  21.0   \n",
       "18  0.80271   0.0  8.14  0.0  0.538  5.456   36.6  3.7965  4.0  307.0  21.0   \n",
       "\n",
       "        11     12  PRICE  \n",
       "0   396.90   4.98   24.0  \n",
       "1   396.90   9.14   21.6  \n",
       "2   392.83   4.03   34.7  \n",
       "3   394.63   2.94   33.4  \n",
       "4   396.90   5.33   36.2  \n",
       "5   394.12   5.21   28.7  \n",
       "6   395.60  12.43   22.9  \n",
       "7   396.90  19.15   27.1  \n",
       "8   386.63  29.93   16.5  \n",
       "9   386.71  17.10   18.9  \n",
       "10  392.52  20.45   15.0  \n",
       "11  396.90  13.27   18.9  \n",
       "12  390.50  15.71   21.7  \n",
       "13  396.90   8.26   20.4  \n",
       "14  380.02  10.26   18.2  \n",
       "15  395.62   8.47   19.9  \n",
       "16  386.85   6.58   23.1  \n",
       "17  386.75  14.67   17.5  \n",
       "18  288.99  11.69   20.2  "
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston_df.head(19)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda3]",
   "language": "python",
   "name": "conda-env-Anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
